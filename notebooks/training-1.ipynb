{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc121e30a2defb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mglyph as mg\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from IPython.display import clear_output, display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "import mglyph_ml.lib as lib\n",
    "from mglyph_ml.glyph_importer import GlyphImporter\n",
    "from mglyph_ml.manifest_parsing import Manifest\n",
    "from mglyph_ml.data.glyph_dataset import GlyphDataset, GlyphSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaed668",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1e3af894b4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we simply set up a glyph provider that out GlyphDataset will use to load glyphs from the export\n",
    "train_glyphs = [\"train-square.mglyph\", \"train-triangle.mglyph\", \"train-circle.mglyph\"]\n",
    "importers_train = [\n",
    "    GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in train_glyphs\n",
    "]\n",
    "dataset_train: GlyphDataset = GlyphDataset(*importers_train)\n",
    "\n",
    "test_glyphs = [\"test-square.mglyph\", \"test-triangle.mglyph\", \"test-circle.mglyph\"]\n",
    "importers_test = [\n",
    "    GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in test_glyphs\n",
    "]\n",
    "dataset_test: GlyphDataset = GlyphDataset(\n",
    "    *importers_test\n",
    ")  # Changed from importers_train to importers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a temporary dataset with normalization turned off so that we can see that is fed into the NN\n",
    "temp_dataset: GlyphDataset = GlyphDataset(*importers_test, normalize=False)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "for index, data in enumerate(temp_dataset.get_random_samples(n=9)):\n",
    "    image, label = data\n",
    "    # get row and column index for the subplot\n",
    "    row = index // 3\n",
    "    col = index % 3\n",
    "\n",
    "    img = image.numpy().clip(0, 1).transpose(1, 2, 0)  # [C, H, W] -> [H, W, C]\n",
    "\n",
    "    # display the image\n",
    "    axes[row, col].imshow(img)\n",
    "    axes[row, col].set_title(f\"{label:.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95639c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity check before training\n",
    "# we check that the input data is of the expected shape and properly normalized\n",
    "print(\"Sample image shape:\", dataset_train[0][0])\n",
    "print(\"Sample label:\", dataset_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530eafb9ca5adfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    train_data_loader: DataLoader,\n",
    "    criterion,  # unfortunately, has no supertype... There's torch.nn.modules._Loss, but it's private\n",
    "    optimizer,  # same as above\n",
    ") -> float:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for index, data in enumerate(train_data_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        # Optionally print every N batches\n",
    "        # if (i + 1) % 10 == 0:\n",
    "        # print(f\"[Epoch {epoch+1}, Batch {i+1}] loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / num_batches if num_batches > 0 else 0.0\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we create the model\n",
    "from mglyph_ml.nn.glyph_regressor_gen2 import GlyphRegressor\n",
    "model = GlyphRegressor()\n",
    "# we move the model to the GPU for much faster training (if GPU is available)\n",
    "if device == 'cuda':\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_debug = list(range(0, len(dataset_train), 16))\n",
    "dataset_debug = Subset(dataset_train, indices_debug)\n",
    "\n",
    "# simply change the dataset to any other, and train :)\n",
    "# data_loader_train = DataLoader(dataset_debug, batch_size=16, shuffle=True)\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0003, momentum=0.00001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "ax2 = ax1.twinx()\n",
    "losses = []\n",
    "accuracies = []\n",
    "# Train for 5 epochs\n",
    "for epoch in range(10):\n",
    "    loss = train_one_epoch(model, data_loader_train, criterion, optimizer)\n",
    "    error = loss * 10_000\n",
    "    losses.append(loss)\n",
    "    accuracies.append(error)\n",
    "    \n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    \n",
    "    # Plot updated data with markers\n",
    "    ax1.plot(range(len(losses)), losses, color='blue', label='Loss', marker='o', markersize=4)\n",
    "    ax2.plot(range(len(accuracies)), accuracies, color='red', label='Accuracy', marker='o', markersize=4)\n",
    "    \n",
    "    # Set labels and x-axis ticks\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_xticks(range(len(losses)))\n",
    "    fig.legend(loc='upper right')\n",
    "    \n",
    "    # Update display\n",
    "    clear_output(wait=True)\n",
    "    print(f\"E={epoch}; L={loss:.8f}; error={error:.2f}\")\n",
    "    if error < 0.3:\n",
    "        break\n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading the model!\n",
    "torch.save(model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b43806366826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Generate 10 random indices from the test set\n",
    "    print(\"===TEST DATASET===\")\n",
    "    random_indices = torch.randint(0, len(dataset_test), size=(10,)).tolist()\n",
    "    for idx in random_indices:\n",
    "        input, label = dataset_test[idx]\n",
    "        # add batch dimension: (C,H,W) -> (1,C,H,W)\n",
    "        img_batch = input.unsqueeze(0)\n",
    "        pred = model(img_batch).item()\n",
    "        print(f\"True: {label * 100:.1f}, Predicted: {pred * 100:.1f}\")\n",
    "    print(\"=====train set======\")\n",
    "    random_indices = torch.randint(0, len(dataset_train), size=(10,)).tolist()\n",
    "    for idx in random_indices:\n",
    "        input, label = dataset_train[idx]\n",
    "        # add batch dimension: (C,H,W) -> (1,C,H,W)\n",
    "        img_batch = input.unsqueeze(0)\n",
    "        pred = model(img_batch).item()\n",
    "        print(f\"True: {label * 100:.1f}, Predicted: {pred * 100:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e015aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all examples and collect errors\n",
    "# model = model.to('cpu')\n",
    "# train_errors = []\n",
    "# test_errors = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # Evaluate training set\n",
    "#     for i in range(len(dataset_train)):\n",
    "#         input, label = dataset_train[i]\n",
    "#         img_batch = input.unsqueeze(0)\n",
    "#         pred = model(img_batch).item()\n",
    "#         error = (pred - label) * 100\n",
    "#         train_errors.append(error)\n",
    "    \n",
    "#     # Evaluate test set\n",
    "#     for i in range(len(dataset_test)):\n",
    "#         input, label = dataset_test[i]\n",
    "#         img_batch = input.unsqueeze(0)\n",
    "#         pred = model(img_batch).item()\n",
    "#         error = (pred - label) * 100\n",
    "#         test_errors.append(error)\n",
    "\n",
    "train_mean = np.mean(train_errors)\n",
    "train_std = np.std(train_errors)\n",
    "test_mean = np.mean(test_errors)\n",
    "test_std = np.std(test_errors)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bins = np.linspace(min(min(train_errors), min(test_errors)), \n",
    "                   max(max(train_errors), max(test_errors)), 50)\n",
    "\n",
    "plt.hist(train_errors, bins=bins, alpha=0.5, label=f'Training (μ={train_mean:.2f}, σ={train_std:.2f})', \n",
    "         density=True, color='blue')\n",
    "plt.hist(test_errors, bins=bins, alpha=0.5, label=f'Test (μ={test_mean:.2f}, σ={test_std:.2f})', \n",
    "         density=True, color='red')\n",
    "\n",
    "plt.xlabel('Prediction Error (units of x)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Prediction Errors on Training and Test Sets')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "print(f\"Training Set Statistics:\")\n",
    "print(f\"  Mean Error: {train_mean:.2f}%\")\n",
    "print(f\"  Std Dev:    {train_std:.2f}%\")\n",
    "print(f\"  Min Error:  {min(train_errors):.2f}%\")\n",
    "print(f\"  Max Error:  {max(train_errors):.2f}%\")\n",
    "print(f\"\\nTest Set Statistics:\")\n",
    "print(f\"  Mean Error: {test_mean:.2f}%\")\n",
    "print(f\"  Std Dev:    {test_std:.2f}%\")\n",
    "print(f\"  Min Error:  {min(test_errors):.2f}%\")\n",
    "print(f\"  Max Error:  {max(test_errors):.2f}%\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we can analyze the model a little bit, see what it's doing internally\n",
    "def visualize_kernels(model: GlyphRegressor, layer_idx: int = 0, ncols: int = 8, figsize=(10,10), cmap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Visualize convolution kernels from the model's feature extractor.\n",
    "    - If kernel has 3 input channels, shows as RGB.\n",
    "    - Otherwise shows averaged (grayscale) kernel per output channel.\n",
    "    - layer_idx: 0 for first conv, 1 for second conv, 2 for third conv\n",
    "    \"\"\"\n",
    "    # get the conv layer from sequential\n",
    "    conv_layers = [module for module in model.features if isinstance(module, nn.Conv2d)]\n",
    "    if layer_idx >= len(conv_layers):\n",
    "        raise ValueError(f\"Layer index {layer_idx} is out of range. Model has {len(conv_layers)} conv layers.\")\n",
    "    \n",
    "    layer = conv_layers[layer_idx]\n",
    "    weight = layer.weight.detach().cpu()  # shape: (out_ch, in_ch, kH, kW)\n",
    "    out_ch, in_ch, _, _ = weight.shape\n",
    "\n",
    "    nrows = math.ceil(out_ch / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i in range(nrows * ncols):\n",
    "        ax = axes[i]\n",
    "        ax.axis(\"off\")\n",
    "        if i >= out_ch:\n",
    "            continue\n",
    "        kern = weight[i]  # (in_ch, kH, kW)\n",
    "        if in_ch == 3:\n",
    "            # to H,W,C for display; normalize per-filter\n",
    "            img = kern.permute(1, 2, 0).numpy()\n",
    "            # normalize to 0..1\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"f{i} (RGB)\")\n",
    "        else:\n",
    "            # average across input channels -> single plane\n",
    "            img = kern.mean(dim=0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "            ax.set_title(f\"f{i} (avg)\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# After training\n",
    "# Visualize the three convolutional layers\n",
    "fig1 = visualize_kernels(model, layer_idx=0, ncols=4, figsize=(8,8))  # First conv (16 kernels)\n",
    "plt.show()\n",
    "fig2 = visualize_kernels(model, layer_idx=1, ncols=8, figsize=(8,4))  # Second conv (32 kernels)\n",
    "plt.show()\n",
    "fig3 = visualize_kernels(model, layer_idx=2, ncols=8, figsize=(8,8))  # Third conv (64 kernels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ace7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def export_kernels(model: torch.nn.Module, layer_name: str, out_dir: str, cmap: str = \"viridis\"):\n",
    "    \"\"\"\n",
    "    Export all kernels from a specified convolutional layer to images in `out_dir`.\n",
    "    - If kernels have 3 input channels, saves as RGB images.\n",
    "    - Otherwise, saves as grayscale images (averaged over input channels).\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    layer = getattr(model, layer_name, None)\n",
    "    if layer is None:\n",
    "        raise ValueError(f\"Model has no attribute '{layer_name}'\")\n",
    "    weight = layer.weight.detach().cpu()  # (out_ch, in_ch, kH, kW)\n",
    "    out_ch, in_ch, kH, kW = weight.shape\n",
    "    for i in range(out_ch):\n",
    "        kern = weight[i]  # (in_ch, kH, kW)\n",
    "        if in_ch == 3:\n",
    "            # RGB kernel: (3, kH, kW) -> (kH, kW, 3)\n",
    "            img = kern.permute(1, 2, 0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img, mode=\"RGB\")\n",
    "        else:\n",
    "            # Grayscale: average over input channels\n",
    "            img = kern.mean(dim=0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img, mode=\"L\")\n",
    "        out_path = os.path.join(out_dir, f\"{layer_name}_kernel_{i}.png\")\n",
    "        im.save(out_path)\n",
    "    print(f\"Exported {out_ch} kernels from '{layer_name}' to {out_dir}\")\n",
    "\n",
    "export_kernels(model=model, layer_name=\"conv3\", out_dir=\"data/kernels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mglyph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
