{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc121e30a2defb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "from importlib import reload\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mglyph as mg\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from IPython.display import clear_output, display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "import mglyph_ml\n",
    "import mglyph_ml.lib as lib\n",
    "from mglyph_ml.data.glyph_dataset import GlyphDataset, GlyphSample\n",
    "from mglyph_ml.glyph_importer import GlyphImporter\n",
    "from mglyph_ml.manifest_parsing import Manifest\n",
    "from mglyph_ml.nn.utils import train_one_epoch\n",
    "\n",
    "reload(mglyph_ml) # TODO: doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaed668",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1e3af894b4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we simply set up a glyph provider that out GlyphDataset will use to load glyphs from the export\n",
    "train_glyphs = [\"train-square.mglyph\", \"train-triangle.mglyph\", \"train-circle.mglyph\"]\n",
    "importers_train = [\n",
    "    GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in train_glyphs\n",
    "]\n",
    "dataset_train: GlyphDataset = GlyphDataset(*importers_train)\n",
    "\n",
    "test_glyphs = [\"test-square.mglyph\", \"test-triangle.mglyph\", \"test-circle.mglyph\"]\n",
    "importers_test = [\n",
    "    GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in test_glyphs\n",
    "]\n",
    "dataset_test: GlyphDataset = GlyphDataset(\n",
    "    *importers_test\n",
    ")  # Changed from importers_train to importers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a temporary dataset with normalization turned off so that we can see what exactly is fed into the NN\n",
    "temp_dataset: GlyphDataset = GlyphDataset(*importers_test, normalize=False, augmentation_seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get a couple of random indices from the dataset so that we can test if the augmentation\n",
    "# is always the same\n",
    "random_sample_indices = random.sample(range(len(temp_dataset)), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset.reset_transform()  # works!!!\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "for index, data in enumerate([temp_dataset[i] for i in random_sample_indices]):\n",
    "    image, label = data\n",
    "    # get row and column index for the subplot\n",
    "    row = index // 3\n",
    "    col = index % 3\n",
    "\n",
    "    img = image.numpy().clip(0, 1).transpose(1, 2, 0)  # [C, H, W] -> [H, W, C]\n",
    "\n",
    "    # display the image\n",
    "    axes[row, col].imshow(img)\n",
    "    axes[row, col].set_title(f\"{label:.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95639c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity check before training\n",
    "# we check that the input data is of the expected shape and properly normalized\n",
    "print(\"Sample image shape:\", dataset_train[0][0])\n",
    "print(\"Sample label:\", dataset_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we create the model\n",
    "from mglyph_ml.nn.glyph_regressor_gen2 import GlyphRegressor\n",
    "model = GlyphRegressor()\n",
    "# we move the model to the GPU for much faster training (if GPU is available)\n",
    "if device == 'cuda':\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_glyph_regressor(\n",
    "    model: nn.Module, \n",
    "    data_loader: DataLoader, \n",
    "    device: str, \n",
    "    criterion\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Takes a glyph regressor, temporarily disables gradient calculation, and calculates the average\n",
    "    loss on the given dataset (DataLoader). Processes in batches on GPU for efficiency.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.view(-1, 1)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    avg_loss = running_loss / num_batches if num_batches > 0 else 0.0\n",
    "    model.train()  # Set model back to training mode\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_debug = list(range(0, len(dataset_train), 16))\n",
    "dataset_debug = Subset(dataset_train, indices_debug)\n",
    "\n",
    "# simply change the dataset to any other, and train :)\n",
    "# data_loader_train = DataLoader(dataset_debug, batch_size=16, shuffle=True)\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=64)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0003, momentum=0.00001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "ax2 = ax1.twinx()\n",
    "losses = []\n",
    "accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Train for 5 epochs\n",
    "for epoch in range(10):\n",
    "    loss = train_one_epoch(model, data_loader_train, device, criterion, optimizer)\n",
    "    error = loss * 10_000\n",
    "    losses.append(loss)\n",
    "    accuracies.append(error)\n",
    "\n",
    "    test_loss = evaluate_glyph_regressor(model, data_loader_test)\n",
    "\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    \n",
    "    # Plot updated data with markers\n",
    "    ax1.plot(range(len(losses)), losses, color='red', label='Train Loss', marker='o', markersize=4)\n",
    "    ax2.plot(range(len(accuracies)), accuracies, color='purple', label='Train Accuracy', marker='o', markersize=4)\n",
    "    ax1.plot(range(len(test_losses)), losses, color='cyan', label='Test Loss', marker='o', markersize=4)\n",
    "    ax2.plot(range(len(test_accuracies)), accuracies, color='green', label='Test Accuracy', marker='o', markersize=4)\n",
    "    \n",
    "    # Set labels and x-axis ticks\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_xticks(range(len(losses)))\n",
    "    fig.legend(loc='upper right')\n",
    "    \n",
    "    # Update display\n",
    "    clear_output(wait=True)\n",
    "    print(f\"E={epoch}; L={loss:.8f}; error={error:.2f}\")\n",
    "    if error < 0.3:\n",
    "        break\n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading the model!\n",
    "# torch.save(model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b43806366826e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e015aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all examples and collect errors\n",
    "# model = model.to('cpu')\n",
    "# train_errors = []\n",
    "# test_errors = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # Evaluate training set\n",
    "#     for i in range(len(dataset_train)):\n",
    "#         input, label = dataset_train[i]\n",
    "#         img_batch = input.unsqueeze(0)\n",
    "#         pred = model(img_batch).item()\n",
    "#         error = (pred - label) * 100\n",
    "#         train_errors.append(error)\n",
    "    \n",
    "#     # Evaluate test set\n",
    "#     for i in range(len(dataset_test)):\n",
    "#         input, label = dataset_test[i]\n",
    "#         img_batch = input.unsqueeze(0)\n",
    "#         pred = model(img_batch).item()\n",
    "#         error = (pred - label) * 100\n",
    "#         test_errors.append(error)\n",
    "\n",
    "train_mean = np.mean(train_errors)\n",
    "train_std = np.std(train_errors)\n",
    "test_mean = np.mean(test_errors)\n",
    "test_std = np.std(test_errors)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bins = np.linspace(min(min(train_errors), min(test_errors)), \n",
    "                   max(max(train_errors), max(test_errors)), 50)\n",
    "\n",
    "plt.hist(train_errors, bins=bins, alpha=0.5, label=f'Training (μ={train_mean:.2f}, σ={train_std:.2f})', \n",
    "         density=True, color='blue')\n",
    "plt.hist(test_errors, bins=bins, alpha=0.5, label=f'Test (μ={test_mean:.2f}, σ={test_std:.2f})', \n",
    "         density=True, color='red')\n",
    "\n",
    "plt.xlabel('Prediction Error (units of x)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Prediction Errors on Training and Test Sets')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "print(f\"Training Set Statistics:\")\n",
    "print(f\"  Mean Error: {train_mean:.2f}%\")\n",
    "print(f\"  Std Dev:    {train_std:.2f}%\")\n",
    "print(f\"  Min Error:  {min(train_errors):.2f}%\")\n",
    "print(f\"  Max Error:  {max(train_errors):.2f}%\")\n",
    "print(f\"\\nTest Set Statistics:\")\n",
    "print(f\"  Mean Error: {test_mean:.2f}%\")\n",
    "print(f\"  Std Dev:    {test_std:.2f}%\")\n",
    "print(f\"  Min Error:  {min(test_errors):.2f}%\")\n",
    "print(f\"  Max Error:  {max(test_errors):.2f}%\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we can analyze the model a little bit, see what it's doing internally\n",
    "def visualize_kernels(model: GlyphRegressor, layer_idx: int = 0, ncols: int = 8, figsize=(10,10), cmap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Visualize convolution kernels from the model's feature extractor.\n",
    "    - If kernel has 3 input channels, shows as RGB.\n",
    "    - Otherwise shows averaged (grayscale) kernel per output channel.\n",
    "    - layer_idx: 0 for first conv, 1 for second conv, 2 for third conv\n",
    "    \"\"\"\n",
    "    # get the conv layer from sequential\n",
    "    conv_layers = [module for module in model.features if isinstance(module, nn.Conv2d)]\n",
    "    if layer_idx >= len(conv_layers):\n",
    "        raise ValueError(f\"Layer index {layer_idx} is out of range. Model has {len(conv_layers)} conv layers.\")\n",
    "    \n",
    "    layer = conv_layers[layer_idx]\n",
    "    weight = layer.weight.detach().cpu()  # shape: (out_ch, in_ch, kH, kW)\n",
    "    out_ch, in_ch, _, _ = weight.shape\n",
    "\n",
    "    nrows = math.ceil(out_ch / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i in range(nrows * ncols):\n",
    "        ax = axes[i]\n",
    "        ax.axis(\"off\")\n",
    "        if i >= out_ch:\n",
    "            continue\n",
    "        kern = weight[i]  # (in_ch, kH, kW)\n",
    "        if in_ch == 3:\n",
    "            # to H,W,C for display; normalize per-filter\n",
    "            img = kern.permute(1, 2, 0).numpy()\n",
    "            # normalize to 0..1\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"f{i} (RGB)\")\n",
    "        else:\n",
    "            # average across input channels -> single plane\n",
    "            img = kern.mean(dim=0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "            ax.set_title(f\"f{i} (avg)\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# After training\n",
    "# Visualize the three convolutional layers\n",
    "fig1 = visualize_kernels(model, layer_idx=0, ncols=4, figsize=(8,8))  # First conv (16 kernels)\n",
    "plt.show()\n",
    "fig2 = visualize_kernels(model, layer_idx=1, ncols=8, figsize=(8,4))  # Second conv (32 kernels)\n",
    "plt.show()\n",
    "fig3 = visualize_kernels(model, layer_idx=2, ncols=8, figsize=(8,8))  # Third conv (64 kernels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ace7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def export_kernels(model: torch.nn.Module, layer_name: str, out_dir: str, cmap: str = \"viridis\"):\n",
    "    \"\"\"\n",
    "    Export all kernels from a specified convolutional layer to images in `out_dir`.\n",
    "    - If kernels have 3 input channels, saves as RGB images.\n",
    "    - Otherwise, saves as grayscale images (averaged over input channels).\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    layer = getattr(model, layer_name, None)\n",
    "    if layer is None:\n",
    "        raise ValueError(f\"Model has no attribute '{layer_name}'\")\n",
    "    weight = layer.weight.detach().cpu()  # (out_ch, in_ch, kH, kW)\n",
    "    out_ch, in_ch, kH, kW = weight.shape\n",
    "    for i in range(out_ch):\n",
    "        kern = weight[i]  # (in_ch, kH, kW)\n",
    "        if in_ch == 3:\n",
    "            # RGB kernel: (3, kH, kW) -> (kH, kW, 3)\n",
    "            img = kern.permute(1, 2, 0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img, mode=\"RGB\")\n",
    "        else:\n",
    "            # Grayscale: average over input channels\n",
    "            img = kern.mean(dim=0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img, mode=\"L\")\n",
    "        out_path = os.path.join(out_dir, f\"{layer_name}_kernel_{i}.png\")\n",
    "        im.save(out_path)\n",
    "    print(f\"Exported {out_ch} kernels from '{layer_name}' to {out_dir}\")\n",
    "\n",
    "export_kernels(model=model, layer_name=\"conv3\", out_dir=\"data/kernels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mglyph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
