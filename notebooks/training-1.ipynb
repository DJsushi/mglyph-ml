{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc121e30a2defb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "from importlib import reload\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mglyph as mg\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from IPython.display import clear_output, display\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "import mglyph_ml\n",
    "import mglyph_ml.lib as lib\n",
    "from mglyph_ml.data.glyph_dataset import GlyphDataset, GlyphSample\n",
    "from mglyph_ml.glyph_importer import GlyphImporter\n",
    "from mglyph_ml.manifest_parsing import Manifest\n",
    "from mglyph_ml.nn.utils import train_one_epoch\n",
    "\n",
    "# Reload all mglyph_ml modules to pick up code changes\n",
    "reload(mglyph_ml.glyph_importer)\n",
    "reload(mglyph_ml.manifest_parsing)\n",
    "reload(mglyph_ml.data.glyph_dataset)\n",
    "reload(mglyph_ml.nn.utils)\n",
    "reload(mglyph_ml.lib)\n",
    "reload(mglyph_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaed668",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1e3af894b4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we simply set up a glyph provider that out GlyphDataset will use to load glyphs from the export\n",
    "train_glyphs = [\"train-square.mglyph\", \"train-triangle.mglyph\", \"train-circle.mglyph\"]\n",
    "importers_train = [\n",
    "    GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in train_glyphs\n",
    "]\n",
    "dataset_train: GlyphDataset = GlyphDataset(*importers_train)\n",
    "\n",
    "test_glyphs = [\"test-square.mglyph\", \"test-triangle.mglyph\", \"test-circle.mglyph\"]\n",
    "importers = [\n",
    "    GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in test_glyphs\n",
    "]\n",
    "dataset_test: GlyphDataset = GlyphDataset(\n",
    "    *importers,\n",
    "    augmentation_seed=69\n",
    ")  # Changed from importers_train to importers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a temporary dataset with normalization turned off so that we can see what exactly is fed into the NN\n",
    "temp_dataset: GlyphDataset = GlyphDataset(*importers, normalize=False, augmentation_seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get a couple of random indices from the dataset so that we can test if the augmentation\n",
    "# is always the same\n",
    "random_sample_indices = random.sample(range(len(temp_dataset)), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random test samples using the utility function\n",
    "from mglyph_ml.nn.utils import visualize_test_samples\n",
    "\n",
    "visualize_test_samples(\n",
    "    importers=importers,\n",
    "    num_samples=12,\n",
    "    figsize=(6, 6),\n",
    "    augmentation_seed=69\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95639c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity check before training\n",
    "# we check that the input data is of the expected shape and properly normalized\n",
    "print(\"Sample image shape:\", dataset_train[0][0])\n",
    "print(\"Sample label:\", dataset_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we create the model\n",
    "from mglyph_ml.nn.glyph_regressor_gen2 import GlyphRegressor\n",
    "model = GlyphRegressor()\n",
    "# we move the model to the GPU for much faster training (if GPU is available)\n",
    "if device == 'cuda':\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_glyph_regressor(\n",
    "    model: nn.Module, \n",
    "    data_loader: DataLoader, \n",
    "    device: str, \n",
    "    criterion\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Takes a glyph regressor, temporarily disables gradient calculation, and calculates the average\n",
    "    loss on the given dataset (DataLoader). Processes in batches on GPU for efficiency.\n",
    "\n",
    "    Returns a tuple containing the average loss and average error (mean absolute error)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_error = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.view(-1, 1)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Calculate error as the average absolute difference (y_hat - y)\n",
    "            error = torch.mean(torch.abs(outputs - labels)).item()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_error += error\n",
    "            num_batches += 1\n",
    "    \n",
    "    avg_loss = running_loss / num_batches if num_batches > 0 else 0.0\n",
    "    avg_error = running_error / num_batches if num_batches > 0 else 0.0\n",
    "    model.train()  # Set model back to training mode\n",
    "    return avg_loss, avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_debug = list(range(0, len(dataset_train), 16))\n",
    "dataset_debug = Subset(dataset_train, indices_debug)\n",
    "\n",
    "# simply change the dataset to any other, and train :)\n",
    "# data_loader_train = DataLoader(dataset_debug, batch_size=16, shuffle=True)\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=64)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0003, momentum=0.00001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "ax2 = ax1.twinx()\n",
    "losses = []\n",
    "errors = []\n",
    "test_losses = []\n",
    "test_errors = []\n",
    "\n",
    "# Train for 10 epochs\n",
    "for epoch in range(10):\n",
    "    loss, error = train_one_epoch(model, data_loader_train, device, criterion, optimizer)\n",
    "    error *= 100.0  # Convert normalized error (0-1) to actual x units (0-100)\n",
    "    losses.append(loss)\n",
    "    errors.append(error)\n",
    "\n",
    "    # reset the dataloaer's transform in order to make the test dataset 100% reproducible\n",
    "    dataset_test.reset_transform()\n",
    "    test_loss, test_error = evaluate_glyph_regressor(model, data_loader_test, device, criterion)\n",
    "    test_error *= 100.0  # Convert normalized error (0-1) to actual x units (0-100)\n",
    "    test_losses.append(test_loss)\n",
    "    test_errors.append(test_error)\n",
    "\n",
    "    # Clear previous plots\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    \n",
    "    # Plot updated data with markers (dashed lines for loss, solid for error)\n",
    "    ax1.plot(range(len(losses)), losses, color='green', label='Train Loss', marker='o', markersize=4, linestyle='--')\n",
    "    ax2.plot(range(len(errors)), errors, color='green', label='Train Error', marker='o', markersize=4, linestyle='-')\n",
    "    ax1.plot(range(len(test_losses)), test_losses, color='red', label='Test Loss', marker='o', markersize=4, linestyle='--')\n",
    "    ax2.plot(range(len(test_errors)), test_errors, color='red', label='Test Error', marker='o', markersize=4, linestyle='-')\n",
    "    \n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    # Set labels and x-axis ticks\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (MSE)', color='black')\n",
    "    ax2.set_ylabel('Error (Mean Absolute Error, x units)', color='black')\n",
    "    ax2.yaxis.set_label_position('right')\n",
    "    ax1.set_xticks(range(len(losses)))\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    # Update display\n",
    "    clear_output(wait=True)\n",
    "    # Early stopping: stop if error is good enough (< 0.3 x units)\n",
    "    if test_error < 0.3:\n",
    "        print(f\"Early stopping at epoch {epoch+1}: test error {test_error:.4f} x units is below threshold\")\n",
    "        display(fig)\n",
    "        break\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44462c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the actual dataset sizes and understand why convergence is fast\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SIZE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Full training dataset size: {len(dataset_train)}\")\n",
    "print(f\"Debug subset size (every 16th): {len(list(range(0, len(dataset_train), 16)))}\")\n",
    "print(f\"Test dataset size: {len(dataset_test)}\")\n",
    "print(f\"\\nBatch size: 64\")\n",
    "print(f\"Batches per epoch (debug): {len(list(range(0, len(dataset_train), 16))) / 64:.1f}\")\n",
    "print(f\"Batches per epoch (full): {len(dataset_train) / 64:.1f}\")\n",
    "print(\"\\nNote: Using only every 16th sample means the model sees very little data!\")\n",
    "print(\"Consider training on the full dataset or increasing the subset size.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading the model!\n",
    "# torch.save(model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b43806366826e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e015aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all examples and collect errors\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Evaluate training set\n",
    "    for i in range(len(dataset_train)):\n",
    "        input, label = dataset_train[i]\n",
    "        img_batch = input.unsqueeze(0).to(device)\n",
    "        pred = model(img_batch).item()\n",
    "        error = (pred - label) * 100  # Convert to x units (0-100)\n",
    "        train_errors.append(error)\n",
    "    \n",
    "    # Evaluate test set\n",
    "    dataset_test.reset_transform()\n",
    "    for i in range(len(dataset_test)):\n",
    "        input, label = dataset_test[i]\n",
    "        img_batch = input.unsqueeze(0).to(device)\n",
    "        pred = model(img_batch).item()\n",
    "        error = (pred - label) * 100  # Convert to x units (0-100)\n",
    "        test_errors.append(error)\n",
    "\n",
    "train_mean = np.mean(train_errors)\n",
    "train_std = np.std(train_errors)\n",
    "test_mean = np.mean(test_errors)\n",
    "test_std = np.std(test_errors)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bins = np.linspace(min(min(train_errors), min(test_errors)), \n",
    "                   max(max(train_errors), max(test_errors)), 50)\n",
    "\n",
    "plt.hist(train_errors, bins=bins, alpha=0.5, label=f'Training (μ={train_mean:.2f}, σ={train_std:.2f})', \n",
    "         density=True, color='blue')\n",
    "plt.hist(test_errors, bins=bins, alpha=0.5, label=f'Test (μ={test_mean:.2f}, σ={test_std:.2f})', \n",
    "         density=True, color='red')\n",
    "\n",
    "plt.xlabel('Prediction Error (x units, 0-100)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Prediction Errors on Training and Test Sets')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "print(f\"Training Set Statistics:\")\n",
    "print(f\"  Mean Error: {train_mean:.2f} x units\")\n",
    "print(f\"  Std Dev:    {train_std:.2f} x units\")\n",
    "print(f\"  Min Error:  {min(train_errors):.2f} x units\")\n",
    "print(f\"  Max Error:  {max(train_errors):.2f} x units\")\n",
    "print(f\"\\nTest Set Statistics:\")\n",
    "print(f\"  Mean Error: {test_mean:.2f} x units\")\n",
    "print(f\"  Std Dev:    {test_std:.2f} x units\")\n",
    "print(f\"  Min Error:  {min(test_errors):.2f} x units\")\n",
    "print(f\"  Max Error:  {max(test_errors):.2f} x units\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on test samples using the utility function\n",
    "from mglyph_ml.nn.utils import visualize_test_predictions\n",
    "\n",
    "visualize_test_predictions(\n",
    "    model=model,\n",
    "    importers=importers,\n",
    "    device=device,\n",
    "    num_samples=9,\n",
    "    figsize=(6, 6),\n",
    "    augmentation_seed=69\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# here, we can analyze the model a little bit, see what it's doing internally\n",
    "def visualize_kernels(model: nn.Module, layer_idx: int = 0, ncols: int = 8, figsize=(10,10), cmap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Visualize convolution kernels from the model's feature extractor.\n",
    "    - If kernel has 3 input channels, shows as RGB.\n",
    "    - Otherwise shows averaged (grayscale) kernel per output channel.\n",
    "    - layer_idx: 0 for first conv, 1 for second conv, 2 for third conv\n",
    "    \"\"\"\n",
    "    # get the conv layer from sequential\n",
    "    conv_layers = [module for module in model.features if isinstance(module, nn.Conv2d)]\n",
    "    if layer_idx >= len(conv_layers):\n",
    "        raise ValueError(f\"Layer index {layer_idx} is out of range. Model has {len(conv_layers)} conv layers.\")\n",
    "    \n",
    "    layer = conv_layers[layer_idx]\n",
    "    weight = layer.weight.detach().cpu()  # shape: (out_ch, in_ch, kH, kW)\n",
    "    out_ch, in_ch, _, _ = weight.shape\n",
    "\n",
    "    nrows = math.ceil(out_ch / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i in range(nrows * ncols):\n",
    "        ax = axes[i]\n",
    "        ax.axis(\"off\")\n",
    "        if i >= out_ch:\n",
    "            continue\n",
    "        kern = weight[i]  # (in_ch, kH, kW)\n",
    "        if in_ch == 3:\n",
    "            # to H,W,C for display; normalize per-filter\n",
    "            img = kern.permute(1, 2, 0).numpy()\n",
    "            # normalize to 0..1\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"f{i} (RGB)\")\n",
    "        else:\n",
    "            # average across input channels -> single plane\n",
    "            img = kern.mean(dim=0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "            ax.set_title(f\"f{i} (avg)\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# After training\n",
    "# Visualize the three convolutional layers\n",
    "fig1 = visualize_kernels(model, layer_idx=0, ncols=4, figsize=(8,8))  # First conv (16 kernels)\n",
    "plt.show()\n",
    "fig2 = visualize_kernels(model, layer_idx=1, ncols=8, figsize=(8,4))  # Second conv (32 kernels)\n",
    "plt.show()\n",
    "fig3 = visualize_kernels(model, layer_idx=2, ncols=8, figsize=(8,8))  # Third conv (64 kernels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ace7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def export_kernels(model: torch.nn.Module, layer_name: str, out_dir: str, cmap: str = \"viridis\"):\n",
    "    \"\"\"\n",
    "    Export all kernels from a specified convolutional layer to images in `out_dir`.\n",
    "    - If kernels have 3 input channels, saves as RGB images.\n",
    "    - Otherwise, saves as grayscale images (averaged over input channels).\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    layer = getattr(model, layer_name, None)\n",
    "    if layer is None:\n",
    "        raise ValueError(f\"Model has no attribute '{layer_name}'\")\n",
    "    weight = layer.weight.detach().cpu()  # (out_ch, in_ch, kH, kW)\n",
    "    out_ch, in_ch, kH, kW = weight.shape\n",
    "    for i in range(out_ch):\n",
    "        kern = weight[i]  # (in_ch, kH, kW)\n",
    "        if in_ch == 3:\n",
    "            # RGB kernel: (3, kH, kW) -> (kH, kW, 3)\n",
    "            img = kern.permute(1, 2, 0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img, mode=\"RGB\")\n",
    "        else:\n",
    "            # Grayscale: average over input channels\n",
    "            img = kern.mean(dim=0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img, mode=\"L\")\n",
    "        out_path = os.path.join(out_dir, f\"{layer_name}_kernel_{i}.png\")\n",
    "        im.save(out_path)\n",
    "    print(f\"Exported {out_ch} kernels from '{layer_name}' to {out_dir}\")\n",
    "\n",
    "export_kernels(model=model, layer_name=\"conv3\", out_dir=\"data/kernels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mglyph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
