{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc121e30a2defb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mglyph as mg\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "import mglyph_ml.lib as lib\n",
    "from mglyph_ml.glyph_importer import GlyphImporter\n",
    "from mglyph_ml.manifest_parsing import Manifest\n",
    "from mglyph_ml.nn.glyph_dataset import GlyphDataset, GlyphSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1e3af894b4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we simply set up a glyph provider that out GlyphDataset will use to load glyphs from the export\n",
    "train_glyphs = [\"train-square.mglyph\", \"train-triangle.mglyph\"]\n",
    "importers_train = [GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in train_glyphs]\n",
    "dataset_train: GlyphDataset = GlyphDataset(*importers_train)\n",
    "\n",
    "test_glyphs = [\"test-square.mglyph\", \"test-triangle.mglyph\"]\n",
    "importers_test = [GlyphImporter(f\"data/glyphs-experiment-1/{glyph}\") for glyph in test_glyphs]\n",
    "dataset_test: GlyphDataset = GlyphDataset(*importers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a temporary dataset with normalization turned off so that we can see that is fed into the NN \n",
    "temp_dataset: GlyphDataset = GlyphDataset(*importers_train, normalize=False)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "for index, data in enumerate(temp_dataset.get_random_samples(n=9)):\n",
    "    image, label = data\n",
    "    # get row and column index for the subplot\n",
    "    row = index // 3\n",
    "    col = index % 3\n",
    "    \n",
    "    img = image.numpy().clip(0, 1).transpose(1, 2, 0)  # [C, H, W] -> [H, W, C]\n",
    "\n",
    "    # display the image\n",
    "    axes[row, col].imshow(img)\n",
    "    axes[row, col].set_title(f'{label:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6e885648b76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlyphRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input: (batch, 3, 512, 512)\n",
    "        # First conv: small kernel (3x3), shallow depth (4)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1)  # (3,512,512) -> (4,512,512)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # (4,512,512) -> (4,256,256)\n",
    "        \n",
    "        # Second conv: medium kernel (5x5), medium depth (8)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=5, padding=2)  # (4,256,256) -> (8,256,256)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # (8,256,256) -> (8,128,128)\n",
    "        \n",
    "        # Third conv: large kernel (7x7), deeper (16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=7, padding=3)  # (8,128,128) -> (16,128,128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # (16,128,128) -> (16,64,64)\n",
    "        \n",
    "        # Reduce spatial size before FC to lower memory\n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((8, 8))  # (16,64,64) -> (16,8,8)\n",
    "        \n",
    "        # Flatten: 16*8*8 = 1024\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First conv block\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second conv block\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Third conv block\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Final pooling and fully connected layers\n",
    "        x = self.adaptivepool(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95639c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity check before training\n",
    "# we check that the input data is of the expected shape and properly normalized\n",
    "print(\"Sample image shape:\", dataset_train[0][0])\n",
    "print(\"Sample label:\", dataset_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530eafb9ca5adfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: GlyphRegressor,\n",
    "    train_data_loader: DataLoader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch: int = 0\n",
    ") -> float:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        inputs, labels = data\n",
    "        # here, since we're training in batches, we sometimes get the output of the NN in\n",
    "        # a Tensor that has this shape: [B, 1] (B - batch size)\n",
    "        # we need to change the dimensions of the labels that get output from our dataloader\n",
    "        # to also match the size, since our dataloader outputs them in the size [B].\n",
    "        # -1 here tells torch to infer the last dimension from the other dimensions (in this\n",
    "        # case, the other dimension is 1)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # print(f\"inputs size: {inputs.shape}\")\n",
    "        # print(f\"Labels: {labels}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            last_loss = running_loss / 100  # loss per batch\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {last_loss:.3f}\")\n",
    "            running_loss = 0.0  # Reset after printing\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we create the model\n",
    "model = GlyphRegressor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0003, momentum=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset_train, batch_size=4, shuffle=True)\n",
    "model = train(data_loader_train)\n",
    "model.eval()\n",
    "\n",
    "# Train for 5 epochs\n",
    "for epoch in range(5):\n",
    "    loss = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "\n",
    "# Later, continue training:\n",
    "for epoch in range(5, 10):\n",
    "    loss = train_one_epoch(model, train_loader, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb4e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b43806366826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Generate 10 random indices from the test set\n",
    "    random_indices = torch.randint(0, len(dataset_test), size=(10,)).tolist()\n",
    "    for idx in random_indices:\n",
    "        input, label = dataset_test[idx]\n",
    "        # add batch dimension: (C,H,W) -> (1,C,H,W)\n",
    "        img_batch = input.unsqueeze(0)\n",
    "        pred = model(img_batch).item()\n",
    "        print(f\"True: {label * 100:.1f}, Predicted: {pred * 100:.1f}\")\n",
    "    print(\"=====train set======\")\n",
    "    random_indices = torch.randint(0, len(dataset_test), size=(10,)).tolist()\n",
    "    for idx in random_indices:\n",
    "        input, label = dataset_test[idx]\n",
    "        # add batch dimension: (C,H,W) -> (1,C,H,W)\n",
    "        img_batch = input.unsqueeze(0)\n",
    "        pred = model(img_batch).item()\n",
    "        print(f\"True: {label * 100:.1f}, Predicted: {pred * 100:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, we can analyze the model a little bit, see what it's doing internally\n",
    "def visualize_kernels(model: torch.nn.Module, layer_name: str = \"conv1\", ncols: int = 8, figsize=(10,10), cmap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Visualize convolution kernels from `model.<layer_name>`.\n",
    "    - If kernel has 3 input channels, shows as RGB.\n",
    "    - Otherwise shows averaged (grayscale) kernel per output channel.\n",
    "    \"\"\"\n",
    "    # get layer\n",
    "    layer = getattr(model, layer_name, None)\n",
    "    if layer is None:\n",
    "        raise ValueError(f\"Model has no attribute '{layer_name}'\")\n",
    "\n",
    "    weight = layer.weight.detach().cpu()  # shape: (out_ch, in_ch, kH, kW)\n",
    "    out_ch, in_ch, kH, kW = weight.shape\n",
    "\n",
    "    nrows = math.ceil(out_ch / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i in range(nrows * ncols):\n",
    "        ax = axes[i]\n",
    "        ax.axis(\"off\")\n",
    "        if i >= out_ch:\n",
    "            continue\n",
    "        kern = weight[i]  # (in_ch, kH, kW)\n",
    "        if in_ch == 3:\n",
    "            # to H,W,C for display; normalize per-filter\n",
    "            img = kern.permute(1, 2, 0).numpy()\n",
    "            # normalize to 0..1\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"f{i} (RGB)\")\n",
    "        else:\n",
    "            # average across input channels -> single plane\n",
    "            img = kern.mean(dim=0).numpy()\n",
    "            mi, ma = img.min(), img.max()\n",
    "            if ma - mi > 0:\n",
    "                img = (img - mi) / (ma - mi)\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "            ax.set_title(f\"f{i} (avg)\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# After training\n",
    "fig1 = visualize_kernels(model, layer_name=\"conv1\", ncols=2, figsize=(4,4))  # 4 kernels\n",
    "plt.show()\n",
    "fig2 = visualize_kernels(model, layer_name=\"conv2\", ncols=4, figsize=(6,4))  # 8 kernels\n",
    "plt.show()\n",
    "fig3 = visualize_kernels(model, layer_name=\"conv3\", ncols=4, figsize=(8,8))  # 16 kernels\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mglyph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
