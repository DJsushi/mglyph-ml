{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2548c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from clearml import Task\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from mglyph_ml.dataset.glyph_dataset import GlyphDataset\n",
    "from mglyph_ml.dataset.manifest import DatasetManifest, ManifestSample\n",
    "from mglyph_ml.experiment.e1.experiment import ExperimentConfig\n",
    "from mglyph_ml.experiment.e1.train_model import train_and_test_model\n",
    "\n",
    "\n",
    "def decode_png_bytes(png_bytes: bytes) -> np.ndarray:\n",
    "    buf = np.frombuffer(png_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(buf, cv2.IMREAD_COLOR)  # HWC, RGB, uint8\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_image_into_ndarray(archive: ZipFile, filename: str) -> np.ndarray:\n",
    "    png_bytes = archive.read(filename)\n",
    "    return decode_png_bytes(png_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ec157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "path = Path(\"../data/uni.mglyph\")\n",
    "\n",
    "config = ExperimentConfig(\n",
    "    task_name=\"Experiment 1.2.1\",\n",
    "    task_tag=\"exp-1.2.1\",\n",
    "    dataset_path=\"../data/uni.mglyph\",\n",
    "    gap_start_x=40.0,\n",
    "    gap_end_x=60.0,\n",
    "    quick=True,\n",
    "    seed=420,\n",
    "    max_iterations=5,\n",
    "    offline=True,\n",
    ")\n",
    "\n",
    "Task.set_offline(config.offline)\n",
    "task: Task = Task.init(project_name=\"mglyph-ml\", task_name=config.task_name)\n",
    "task.add_tags(config.task_tag)\n",
    "task.connect(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading everything... this cell takes the longest time\n",
    "\n",
    "temp_archive = zipfile.ZipFile(path, \"r\")\n",
    "\n",
    "manifest_data = temp_archive.read(\"manifest.json\")\n",
    "manifest = DatasetManifest.model_validate_json(manifest_data)\n",
    "\n",
    "samples_all = manifest.samples[\"uni\"]\n",
    "\n",
    "# Create index mappings for each subset\n",
    "train_indices = [i for i, sample in enumerate(samples_all) if sample.x < 40.0 or sample.x >= 60]\n",
    "gap_indices = [i for i, sample in enumerate(samples_all) if sample.x >= 40.0 and sample.x < 60]\n",
    "test_indices = list(range(len(samples_all)))\n",
    "\n",
    "# Get sample subsets using indices\n",
    "manifest_samples_train: list[ManifestSample] = [samples_all[i] for i in train_indices]\n",
    "manifest_samples_gap: list[ManifestSample] = [samples_all[i] for i in gap_indices]\n",
    "manifest_samples_test: list[ManifestSample] = samples_all\n",
    "\n",
    "# Load all images once\n",
    "with ThreadPoolExecutor(max_workers=64) as executor:\n",
    "    images_all = list(\n",
    "        executor.map(lambda sample: load_image_into_ndarray(temp_archive, sample.filename), samples_all)\n",
    "    )\n",
    "\n",
    "# Reference image subsets using indices\n",
    "images_train = [images_all[i] for i in train_indices]\n",
    "images_gap = [images_all[i] for i in gap_indices]\n",
    "images_test = images_all\n",
    "\n",
    "labels_train = [samples_all[i].x for i in train_indices]\n",
    "labels_gap = [samples_all[i].x for i in gap_indices]\n",
    "labels_test = [sample.x for sample in samples_all]\n",
    "\n",
    "temp_archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify RGB format and display sample image\n",
    "print(f\"Number of images: {len(images_train)}\")\n",
    "print(f\"First image type: {type(images_train[0])}\")\n",
    "print(f\"First image dtype: {images_train[0].dtype}\")\n",
    "print(f\"First image shape: {images_train[0].shape}\")\n",
    "print(f\"First image is ndarray: {isinstance(images_train[0], np.ndarray)}\")\n",
    "print(f\"First image in RGB format: {images_train[0].dtype == np.uint8 and len(images_train[0].shape) == 3}\")\n",
    "\n",
    "# Display one sample image (convert BGR to RGB for display)\n",
    "display(Image(data=cv2.imencode('.png', images_train[0])[1].tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = GlyphDataset(images=images_train, labels=labels_train, transform=None)\n",
    "dataset_gap = GlyphDataset(images=images_gap, labels=labels_gap, transform=None)\n",
    "dataset_test = GlyphDataset(images=images_test, labels=labels_test, transform=None)\n",
    "\n",
    "train_and_test_model(\n",
    "    dataset_train=dataset_train,\n",
    "    dataset_gap=dataset_gap,\n",
    "    dataset_test=dataset_test,\n",
    "    seed=420,\n",
    "    data_loader_num_workers=8,\n",
    "    batch_size=32,\n",
    "    quick=True,\n",
    "    max_epochs=5,\n",
    "    model_save_path=Path(\"../models/exp1.pt\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mglyph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
