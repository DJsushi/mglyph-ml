{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2548c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from clearml import Task\n",
    "from dotenv import load_dotenv\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mglyph_ml.dataset.glyph_dataset import GlyphDataset\n",
    "from mglyph_ml.dataset.manifest import DatasetManifest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a7bd1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "task_name = \"Experiment 1.2.3\"\n",
    "task_tag = \"exp-1.2.3\"\n",
    "dataset_path = Path(\"data/uni.mglyph\")\n",
    "gap_start_x = 0.0\n",
    "gap_end_x = 3.0\n",
    "seed = 420\n",
    "max_epochs = 10\n",
    "offline = False\n",
    "batch_size = 92\n",
    "data_loader_num_workers = 40\n",
    "n_of_gap_samples = 5000\n",
    "n_of_overall_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ec157",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task.set_offline(offline)\n",
    "task: Task = Task.init(project_name=\"mglyph-ml\", task_name=task_name)\n",
    "task.add_tags(task_tag)\n",
    "logger = Task.current_task().logger\n",
    "load_dotenv()\n",
    "\n",
    "task.connect({\n",
    "    \"dataset_path\": str(dataset_path),\n",
    "    \"gap_start_x\": gap_start_x,\n",
    "    \"gap_end_x\": gap_end_x,\n",
    "    \"seed\": seed,\n",
    "    \"max_epochs\": max_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"data_loader_num_workers\": data_loader_num_workers,\n",
    "    \"n_of_gap_samples\": n_of_gap_samples,\n",
    "    \"n_of_overall_samples\": n_of_overall_samples,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading everything... this cell takes the longest time\n",
    "# Load the entire zip file into memory\n",
    "with open(dataset_path, \"rb\") as f:\n",
    "    temp_archive = ZipFile(BytesIO(f.read()))\n",
    "\n",
    "manifest_data = temp_archive.read(\"manifest.json\")\n",
    "manifest = DatasetManifest.model_validate_json(manifest_data)\n",
    "\n",
    "samples_0 = manifest.samples[\"0\"]  # this is where the training and validation data comes from\n",
    "samples_1 = manifest.samples[\"1\"]  # this is where the test data comes from\n",
    "\n",
    "print(f\"samples_0 count: {len(samples_0)}\")\n",
    "print(f\"samples_1 count: {len(samples_1)}\")\n",
    "\n",
    "# Create index mappings for each subset\n",
    "_eval_rng = random.Random(seed)\n",
    "\n",
    "indices_train = [i for i, sample in enumerate(samples_0) if sample.x < gap_start_x or sample.x >= gap_end_x]\n",
    "\n",
    "indices_gap = [i for i, sample in enumerate(samples_0) if sample.x >= gap_start_x and sample.x < gap_end_x]\n",
    "n_gap_actual = min(n_of_gap_samples, len(indices_gap))\n",
    "indices_gap = _eval_rng.sample(indices_gap, n_gap_actual)\n",
    "indices_gap.sort()\n",
    "\n",
    "all_indices_1 = list(range(len(samples_1)))\n",
    "n_overall_actual = min(n_of_overall_samples, len(all_indices_1))\n",
    "indices_overall = _eval_rng.sample(all_indices_1, n_overall_actual)\n",
    "indices_overall.sort()\n",
    "\n",
    "# Load all images from memory using OpenCV (faster than PIL, directly to numpy)\n",
    "def load_image_cv2(sample):\n",
    "    img_bytes = temp_archive.read(sample.filename)\n",
    "    img_array = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "    # OpenCV loads in BGR, convert to RGB\n",
    "    return img_array\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    images_0 = list(executor.map(load_image_cv2, samples_0))\n",
    "    images_1 = list(executor.map(load_image_cv2, samples_1))\n",
    "\n",
    "temp_archive.close()\n",
    "\n",
    "print(f\"gap eval samples:     {len(indices_gap)}\")\n",
    "print(f\"overall eval samples: {len(indices_overall)}\")\n",
    "\n",
    "# Reference image subsets using indices\n",
    "images_train = [images_0[i] for i in indices_train]\n",
    "images_gap = [images_0[i] for i in indices_gap]\n",
    "images_overall = [images_0[i] for i in indices_overall]\n",
    "\n",
    "labels_train = [samples_0[i].x for i in indices_train]\n",
    "labels_gap = [samples_0[i].x for i in indices_gap]\n",
    "labels_overall = [samples_0[i].x for i in indices_overall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b755bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset creation\n",
    "affine = A.Affine(\n",
    "    rotate=(-3, 3),\n",
    "    translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)},\n",
    "    fit_output=False,\n",
    "    keep_ratio=True,\n",
    "    border_mode=cv2.BORDER_CONSTANT,\n",
    "    fill=255,\n",
    "    p=1.0,\n",
    ")\n",
    "normalize = A.Normalize(mean=0.0, std=1.0, max_pixel_value=255.0)\n",
    "to_tensor = ToTensorV2()\n",
    "pipeline = A.Compose([affine, normalize, to_tensor], seed=seed)\n",
    "normalize_pipeline = A.Compose([normalize, to_tensor])\n",
    "\n",
    "\n",
    "def affine_and_normalize(image: np.ndarray) -> torch.Tensor:\n",
    "    return pipeline(image=image)[\"image\"]\n",
    "\n",
    "\n",
    "def just_normalize(image: np.ndarray) -> torch.Tensor:\n",
    "    return normalize_pipeline(image=image)[\"image\"]\n",
    "\n",
    "\n",
    "dataset_train = GlyphDataset(images=images_train, labels=labels_train, transform=affine_and_normalize)\n",
    "dataset_gap = GlyphDataset(images=images_gap, labels=labels_gap, transform=just_normalize)\n",
    "dataset_overall = GlyphDataset(images=images_overall, labels=labels_overall, transform=just_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from datasets\n",
    "\n",
    "x_samples = 6\n",
    "\n",
    "fig, axes = plt.subplots(3, x_samples, figsize=(2 * x_samples, 5))\n",
    "\n",
    "# training images\n",
    "for i in range(x_samples):\n",
    "    idx = i * len(dataset_train) // x_samples + len(dataset_train) // x_samples // 2\n",
    "    img_tensor, label = dataset_train[idx]\n",
    "    img = img_tensor.permute(1, 2, 0).numpy()\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f\"Train: {label * 100.0:.3f}\")\n",
    "\n",
    "# gap images\n",
    "for i in range(x_samples):\n",
    "    if n_gap_actual == 0:\n",
    "        break\n",
    "    idx = i * len(dataset_gap) // x_samples + len(dataset_gap) // x_samples // 2\n",
    "    img_tensor, label = dataset_gap[idx]\n",
    "    img = img_tensor.permute(1, 2, 0).numpy()\n",
    "    axes[1, i].imshow(img)\n",
    "    axes[1, i].set_title(f\"Gap: {label * 100.0:.3f}\")\n",
    "\n",
    "# test images\n",
    "for i in range(x_samples):\n",
    "    idx = i * len(dataset_overall) // x_samples + len(dataset_overall) // x_samples // 2\n",
    "    img_tensor, label = dataset_overall[idx]\n",
    "    img = img_tensor.permute(1, 2, 0).numpy()\n",
    "    axes[2, i].imshow(img)\n",
    "    axes[2, i].set_title(f\"Overall: {label * 100.0:.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mglyph_ml.nn.glyph_regressor_gen2 import GlyphRegressor\n",
    "\n",
    "device = os.environ[\"MGML_DEVICE\"]\n",
    "print(f\"Training device: {device}\")\n",
    "model = GlyphRegressor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model = model.to(device)\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=data_loader_num_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    generator=generator,\n",
    ")\n",
    "data_loader_gap: DataLoader | None = DataLoader(\n",
    "    dataset_gap,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=data_loader_num_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    generator=generator,\n",
    ") if n_gap_actual != 0 else None\n",
    "data_loader_overall = DataLoader(\n",
    "    dataset_overall,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=data_loader_num_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    generator=generator,\n",
    ")\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    model.train()\n",
    "    epoch_start_time = time.time()\n",
    "    running_train_loss = 0.0\n",
    "    running_error_train = 0.0\n",
    "    num_batches_train = 0\n",
    "\n",
    "    for index, data in enumerate(data_loader_train):\n",
    "        inputs, labels = data\n",
    "        inputs: torch.Tensor = inputs.to(device)\n",
    "        labels: torch.Tensor = labels.to(device)\n",
    "\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float().view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs: torch.Tensor = model(inputs)\n",
    "        loss = criterion(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        error = torch.mean(torch.abs(outputs.float() - labels.float())).item()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        running_error_train += error\n",
    "        num_batches_train += 1\n",
    "\n",
    "    # Calculate average training metrics\n",
    "    avg_train_loss = running_train_loss / num_batches_train\n",
    "    avg_train_error = running_error_train / num_batches_train  # MAE in normalized space (0-1)\n",
    "    avg_train_error_x = avg_train_error * 100.0  # MAE in x space (0-100)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Gap evaluation (x in [gap_start_x, gap_end_x))\n",
    "    avg_gap_loss: float | None = None\n",
    "    avg_gap_error: float | None = None\n",
    "    avg_gap_error_x: float | None = None\n",
    "\n",
    "    if data_loader_gap is not None:\n",
    "        running_loss_gap = 0.0\n",
    "        running_error_gap = 0.0\n",
    "        num_batches_gap = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in data_loader_gap:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.view(-1, 1)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                error = torch.mean(torch.abs(outputs - labels)).item()\n",
    "\n",
    "                running_loss_gap += loss.item()\n",
    "                running_error_gap += error\n",
    "                num_batches_gap += 1\n",
    "\n",
    "        avg_gap_loss = running_loss_gap / num_batches_gap\n",
    "        avg_gap_error = running_error_gap / num_batches_gap  # MAE in normalized space (0-1)\n",
    "        avg_gap_error_x = avg_gap_error * 100.0  # MAE in x space (0-100)\n",
    "\n",
    "    # Overall evaluation (full 0-100 range)\n",
    "    running_loss_overall = 0.0\n",
    "    running_error_overall = 0.0\n",
    "    num_batches_overall = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader_overall:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.view(-1, 1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            error = torch.mean(torch.abs(outputs - labels)).item()\n",
    "\n",
    "            running_loss_overall += loss.item()\n",
    "            running_error_overall += error\n",
    "            num_batches_overall += 1\n",
    "\n",
    "    avg_overall_loss = running_loss_overall / num_batches_overall\n",
    "    avg_overall_error = running_error_overall / num_batches_overall  # MAE in normalized space (0-1)\n",
    "    avg_overall_error_x = avg_overall_error * 100.0  # MAE in x space (0-100)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "    # Log metrics to ClearML\n",
    "    logger.report_scalar(title=\"Loss\", series=\"Train\", value=avg_train_loss, iteration=epoch)\n",
    "    logger.report_scalar(title=\"MAE (normalized)\", series=\"Train\", value=avg_train_error, iteration=epoch)\n",
    "    logger.report_scalar(title=\"MAE (x-space)\", series=\"Train\", value=avg_train_error_x, iteration=epoch)\n",
    "\n",
    "    if avg_gap_loss is not None and avg_gap_error is not None and avg_gap_error_x is not None:\n",
    "        logger.report_scalar(title=\"Loss\", series=\"Gap\", value=avg_gap_loss, iteration=epoch)\n",
    "        logger.report_scalar(title=\"MAE (normalized)\", series=\"Gap\", value=avg_gap_error, iteration=epoch)\n",
    "        logger.report_scalar(title=\"MAE (x-space)\", series=\"Gap\", value=avg_gap_error_x, iteration=epoch)\n",
    "\n",
    "    logger.report_scalar(title=\"Loss\", series=\"Overall\", value=avg_overall_loss, iteration=epoch)\n",
    "    logger.report_scalar(title=\"MAE (normalized)\", series=\"Overall\", value=avg_overall_error, iteration=epoch)\n",
    "    logger.report_scalar(title=\"MAE (x-space)\", series=\"Overall\", value=avg_overall_error_x, iteration=epoch)\n",
    "\n",
    "    logger.report_scalar(title=\"Timing\", series=\"Epoch Duration (s)\", value=epoch_time, iteration=epoch)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"=\" * 80)\n",
    "    print(f\"Epoch {epoch}/{max_epochs}\")\n",
    "    print(f\"-\" * 80)\n",
    "    print(f\"  Train Loss:      {avg_train_loss:.6f}  |  Train MAE (x):   {avg_train_error_x:.4f}\")\n",
    "    if avg_gap_loss is not None and avg_gap_error_x is not None:\n",
    "        print(f\"  Gap Loss:        {avg_gap_loss:.6f}  |  Gap MAE (x):     {avg_gap_error_x:.4f}\")\n",
    "    print(f\"  Overall Loss:    {avg_overall_loss:.6f}  |  Overall MAE (x): {avg_overall_error_x:.4f}\")\n",
    "    print(f\"  Epoch Time:      {epoch_time:.2f}s\")\n",
    "    print(f\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst-case baseline: random predictor (guesses uniformly from 0â€“100)\n",
    "np.random.seed(seed)\n",
    "\n",
    "rand_preds_gap     = np.random.uniform(0.0, 100.0, len(labels_gap))\n",
    "rand_preds_overall = np.random.uniform(0.0, 100.0, len(labels_overall))\n",
    "\n",
    "worst_mae_gap     = np.mean(np.abs(rand_preds_gap     - np.array(labels_gap)))\n",
    "worst_mae_overall = np.mean(np.abs(rand_preds_overall - np.array(labels_overall)))\n",
    "\n",
    "logger.report_scalar(title=\"MAE (x-space)\", series=\"Worst-case Gap\",     value=worst_mae_gap,     iteration=0)\n",
    "logger.report_scalar(title=\"MAE (x-space)\", series=\"Worst-case Overall\",  value=worst_mae_overall, iteration=0)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Worst-case predictor (random 0-100 guesses)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Gap MAE (x-space):     {worst_mae_gap:.4f}\")\n",
    "print(f\"Overall MAE (x-space): {worst_mae_overall:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mglyph-ml (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
