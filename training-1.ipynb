{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:36:21.417702Z",
     "start_time": "2025-11-05T18:36:21.415040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import mglyph as mg\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "import lib\n",
    "from manifest_parsing import Manifest"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Building the training set",
   "id": "adc1915fa4bf5184"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:20:23.382418Z",
     "start_time": "2025-11-05T18:20:17.370731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def square(x: float, canvas: mg.Canvas):\n",
    "    canvas.tr.scale(mg.lerp(x, 0.2, 0.95))\n",
    "    canvas.rect(canvas.top_left, canvas.bottom_right, color=\"red\")\n",
    "\n",
    "\n",
    "lib.export_glyph(square, name=\"square\", glyph_set=\"1\")"
   ],
   "id": "8918c4a38c979919",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntProgress(value=0, description='Exporting square 1.0.0:', max=1000, style=ProgressStyle(bar_color='cornfloweâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3659567e9dd54613802797e9659598de"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting square 1.0.0 finished!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:20:27.034249Z",
     "start_time": "2025-11-05T18:20:24.447472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# here, we need to load the glyph and convert it into a format that'll be accepted by the NN\n",
    "glyph_location: str = \"data/glyphs-1/square.mglyph\"\n",
    "\n",
    "# it's a ZIP file, so we need to unzip it into memory\n",
    "archive: ZipFile = zipfile.ZipFile(glyph_location)\n",
    "\n",
    "# We import the manifest as a Pydantic model, so it's much easier to work with later\n",
    "manifest = archive.read(\"metadata.json\")\n",
    "manifest = Manifest.model_validate_json(manifest)\n",
    "\n",
    "image_size = 50\n",
    "# we loop through the images and load them into RAM from the archive for faster training\n",
    "images: list[tuple[Image.Image, float]] = []\n",
    "for image in manifest.images:\n",
    "    image_data = Image.open(BytesIO(archive.read(image.filename))).convert('L').resize((image_size, image_size))\n",
    "\n",
    "    images.append((image_data, image.x))\n",
    "\n",
    "# we need to convert the images to grayscale first\n",
    "# grayscale_images: list[tuple[bytes, float]] = []\n",
    "# for image in images:\n",
    "#     output = BytesIO()\n",
    "#     Image.open(BytesIO(image)).convert('L').save(output, format=\"png\")\n",
    "# grayscale_images.append(output.getvalue())\n",
    "# grayscale_images = [(Image.open(BytesIO(image[0])).convert('L').resize((image_size, image_size)).tobytes(), image[1]) for image in images]"
   ],
   "id": "73f1e3af894b4228",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:09:14.266369164Z",
     "start_time": "2025-11-05T17:55:49.915152Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58c25477e6bfb8fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:20:27.742122Z",
     "start_time": "2025-11-05T18:20:27.582817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image = images[0][0]\n",
    "# display(image)\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx: int = torch.randint(len(images), size=(1,)).item()\n",
    "    img, label = images[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(str(label))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ],
   "id": "fbbeb785a0177ec3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:42:44.730754Z",
     "start_time": "2025-11-05T18:42:44.722359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import Tensor\n",
    "import io\n",
    "\n",
    "\n",
    "# Creating the PyTorch Dataset and DataLoader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, zip_path: str):\n",
    "        self.zip_path = zip_path\n",
    "        manifest = archive.read(\"metadata.json\")\n",
    "        self.manifest = Manifest.model_validate_json(manifest)\n",
    "        self.samples = [(sample.filename, sample.x) for sample in self.manifest.images]\n",
    "        self.archive = None\n",
    "\n",
    "    def _ensure_archive(self):\n",
    "        if self.archive is None:\n",
    "            self.archive = zipfile.ZipFile(self.zip_path, 'r')\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[Tensor, float]:\n",
    "        self._ensure_archive()\n",
    "        filename, label = self.samples[index]\n",
    "        img_bytes = self.archive.read(filename)\n",
    "        # Convert to torch uint8 tensor for decode_image\n",
    "        img_tensor = torch.tensor(list(img_bytes), dtype=torch.uint8)\n",
    "        img = torchvision.io.decode_image(img_tensor, mode=ImageReadMode.GRAY)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "dataset = ImageDataset(zip_path=glyph_location)\n",
    "data_loader = torch.utils.data.DataLoader(dataset)"
   ],
   "id": "4151028e6734bfcb",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we've imported the zip file and parsed the manifest, we can build our NN",
   "id": "f6d3d8586b9ced63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:42:28.364234Z",
     "start_time": "2025-11-05T18:42:28.360546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GlyphRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        image_size: assume images are square (image_size x image_size)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # input shape: (1, )\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=5, padding=2)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=0)\n",
    "        # self.fc1 = nn.Linear(32 * (image_size // 2) * (image_size // 2), 64)\n",
    "        # self.fc2 = nn.Linear(64, 1)  # single scalar output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 1, H, W)\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        # x = x.view(x.size(0), -1)  # flatten\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = self.fc2(x)  # raw output\n",
    "        # x = torch.sigmoid(x) * 100  # scale 0-100\n",
    "        x = self.pool(x)\n",
    "        return x\n"
   ],
   "id": "a9d6e885648b76d0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:09:14.267650175Z",
     "start_time": "2025-11-05T16:54:39.628535Z"
    }
   },
   "cell_type": "code",
   "source": "# Creating a da",
   "id": "530eafb9ca5adfca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93470/502842280.py:16: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  img_tensor = torch.from_numpy(img_array).float() / 255.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'triton' has no attribute 'language'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     27\u001B[39m model = GlyphRegressor(image_size).to(device)\n\u001B[32m     28\u001B[39m criterion = nn.MSELoss()\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m optimizer = \u001B[43moptim\u001B[49m\u001B[43m.\u001B[49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[32m     32\u001B[39m num_epochs = \u001B[32m100\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/optim/adam.py:101\u001B[39m, in \u001B[36mAdam.__init__\u001B[39m\u001B[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001B[39m\n\u001B[32m     86\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mTensor betas[1] must be 1-element\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     88\u001B[39m defaults = {\n\u001B[32m     89\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m\"\u001B[39m: lr,\n\u001B[32m     90\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mbetas\u001B[39m\u001B[33m\"\u001B[39m: betas,\n\u001B[32m   (...)\u001B[39m\u001B[32m     99\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdecoupled_weight_decay\u001B[39m\u001B[33m\"\u001B[39m: decoupled_weight_decay,\n\u001B[32m    100\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefaults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m fused:\n\u001B[32m    104\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m differentiable:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:401\u001B[39m, in \u001B[36mOptimizer.__init__\u001B[39m\u001B[34m(self, params, defaults)\u001B[39m\n\u001B[32m    398\u001B[39m     param_groups = [{\u001B[33m\"\u001B[39m\u001B[33mparams\u001B[39m\u001B[33m\"\u001B[39m: param_groups}]\n\u001B[32m    400\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m param_group \u001B[38;5;129;01min\u001B[39;00m param_groups:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madd_param_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_group\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001B[39;00m\n\u001B[32m    404\u001B[39m \u001B[38;5;66;03m# which I don't think exists\u001B[39;00m\n\u001B[32m    405\u001B[39m \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001B[39;00m\n\u001B[32m    406\u001B[39m \u001B[38;5;28mself\u001B[39m._warned_capturable_if_run_uncaptured = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_compile.py:46\u001B[39m, in \u001B[36m_disable_dynamo.<locals>.inner\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     44\u001B[39m disable_fn = \u001B[38;5;28mgetattr\u001B[39m(fn, \u001B[33m\"\u001B[39m\u001B[33m__dynamo_disable\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m disable_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\n\u001B[32m     48\u001B[39m     \u001B[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001B[39;00m\n\u001B[32m     49\u001B[39m     \u001B[38;5;66;03m# already wraps fn in the outer scope.\u001B[39;00m\n\u001B[32m     50\u001B[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/__init__.py:13\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m      8\u001B[39m \u001B[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     14\u001B[39m     aot_compile,\n\u001B[32m     15\u001B[39m     config,\n\u001B[32m     16\u001B[39m     convert_frame,\n\u001B[32m     17\u001B[39m     eval_frame,\n\u001B[32m     18\u001B[39m     functional_export,\n\u001B[32m     19\u001B[39m     resume_execution,\n\u001B[32m     20\u001B[39m )\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbackends\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mregistry\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m list_backends, lookup_backend, register_backend\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcallback\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/aot_compile.py:15\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprecompile_context\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PrecompileContext\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m convert_frame\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mhooks\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Hooks\n\u001B[32m     19\u001B[39m log = logging.getLogger(\u001B[34m__name__\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:57\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcallback\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CallbackTrigger\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdistributed\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_compile_pg\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msymbolic_convert\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TensorifyState\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_guards\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m compile_context, CompileContext, CompileId, tracing\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m structured\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:53\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m     52\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ObservedException, TensorifyScalarRestartAnalysis\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_guards\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tracing, TracingContext\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstructured\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dump_file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/exc.py:45\u001B[39m\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_utils_internal\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_file_path_2\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m counters\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[32m     49\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtypes\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:2417\u001B[39m\n\u001B[32m   2414\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_triton_package():\n\u001B[32m   2415\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtriton\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2417\u001B[39m     common_constant_types.add(\u001B[43mtriton\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlanguage\u001B[49m.dtype)\n\u001B[32m   2419\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2420\u001B[39m \u001B[33;03m    Difference between is_safe_constant and common_constant_types.\u001B[39;00m\n\u001B[32m   2421\u001B[39m \u001B[33;03m    * common_constant_types: Constants would be wrapped by VariableBuilder.wrap_literal\u001B[39;00m\n\u001B[32m   2422\u001B[39m \u001B[33;03m                             as ConstantVariable.\u001B[39;00m\n\u001B[32m   2423\u001B[39m \u001B[33;03m    * is_safe_constant: Constants can be loaded by LOAD_CONST bytecode.\u001B[39;00m\n\u001B[32m   2424\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2427\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mis_safe_constant\u001B[39m(v: Any) -> \u001B[38;5;28mbool\u001B[39m:\n",
      "\u001B[31mAttributeError\u001B[39m: module 'triton' has no attribute 'language'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Looking at the code, I can see there's a typo in the comment and an incomplete line. The code has `# <caret>` followed by a stray `s` character that needs to be removed.\n",
    "\n"
   ],
   "id": "bcebf6744c65d606"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T18:09:14.268168763Z",
     "start_time": "2025-11-04T11:28:55.146189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert grayscale images to tensors\n",
    "X = []\n",
    "y = []\n",
    "for idx, img_bytes in enumerate(grayscale_images):\n",
    "    # Convert bytes to numpy array and reshape\n",
    "    img_array = np.frombuffer(img_bytes, dtype=np.uint8).reshape(image_size, image_size)\n",
    "    # Normalize to [0, 1]\n",
    "    img_tensor = torch.from_numpy(img_array).float() / 255.0\n",
    "    # Add channel dimension\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    X.append(img_tensor)\n",
    "    # Get the corresponding x value from manifest\n",
    "    y.append(manifest.images[idx].x)\n",
    "\n",
    "X = torch.stack(X).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# Initialize the model\n",
    "model = GlyphRegressor(image_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Mini-batch training\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch_X = X[i:i + batch_size]\n",
    "        batch_y = y[i:i + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss / len(X):.4f}')\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'models/glyph_regressor.pth')\n",
    "print(\"Model saved to models/glyph_regressor.pth\")\n"
   ],
   "id": "f7ab83a72d5f2718",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'triton' has no attribute 'language'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 21\u001B[39m\n\u001B[32m     19\u001B[39m model = GlyphRegressor(image_size).to(device)\n\u001B[32m     20\u001B[39m criterion = nn.MSELoss()\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m optimizer = \u001B[43moptim\u001B[49m\u001B[43m.\u001B[49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[32m     24\u001B[39m num_epochs = \u001B[32m100\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/optim/adam.py:101\u001B[39m, in \u001B[36mAdam.__init__\u001B[39m\u001B[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001B[39m\n\u001B[32m     86\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mTensor betas[1] must be 1-element\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     88\u001B[39m defaults = {\n\u001B[32m     89\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m\"\u001B[39m: lr,\n\u001B[32m     90\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mbetas\u001B[39m\u001B[33m\"\u001B[39m: betas,\n\u001B[32m   (...)\u001B[39m\u001B[32m     99\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdecoupled_weight_decay\u001B[39m\u001B[33m\"\u001B[39m: decoupled_weight_decay,\n\u001B[32m    100\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefaults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m fused:\n\u001B[32m    104\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m differentiable:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:401\u001B[39m, in \u001B[36mOptimizer.__init__\u001B[39m\u001B[34m(self, params, defaults)\u001B[39m\n\u001B[32m    398\u001B[39m     param_groups = [{\u001B[33m\"\u001B[39m\u001B[33mparams\u001B[39m\u001B[33m\"\u001B[39m: param_groups}]\n\u001B[32m    400\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m param_group \u001B[38;5;129;01min\u001B[39;00m param_groups:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madd_param_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_group\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001B[39;00m\n\u001B[32m    404\u001B[39m \u001B[38;5;66;03m# which I don't think exists\u001B[39;00m\n\u001B[32m    405\u001B[39m \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001B[39;00m\n\u001B[32m    406\u001B[39m \u001B[38;5;28mself\u001B[39m._warned_capturable_if_run_uncaptured = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_compile.py:46\u001B[39m, in \u001B[36m_disable_dynamo.<locals>.inner\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     44\u001B[39m disable_fn = \u001B[38;5;28mgetattr\u001B[39m(fn, \u001B[33m\"\u001B[39m\u001B[33m__dynamo_disable\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m disable_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\n\u001B[32m     48\u001B[39m     \u001B[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001B[39;00m\n\u001B[32m     49\u001B[39m     \u001B[38;5;66;03m# already wraps fn in the outer scope.\u001B[39;00m\n\u001B[32m     50\u001B[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/__init__.py:13\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m      8\u001B[39m \u001B[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     14\u001B[39m     aot_compile,\n\u001B[32m     15\u001B[39m     config,\n\u001B[32m     16\u001B[39m     convert_frame,\n\u001B[32m     17\u001B[39m     eval_frame,\n\u001B[32m     18\u001B[39m     functional_export,\n\u001B[32m     19\u001B[39m     resume_execution,\n\u001B[32m     20\u001B[39m )\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbackends\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mregistry\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m list_backends, lookup_backend, register_backend\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcallback\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/aot_compile.py:15\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprecompile_context\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PrecompileContext\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m convert_frame\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mhooks\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Hooks\n\u001B[32m     19\u001B[39m log = logging.getLogger(\u001B[34m__name__\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:57\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcallback\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CallbackTrigger\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdistributed\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_compile_pg\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msymbolic_convert\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TensorifyState\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_guards\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m compile_context, CompileContext, CompileId, tracing\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m structured\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:53\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m     52\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_dynamo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ObservedException, TensorifyScalarRestartAnalysis\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_guards\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m tracing, TracingContext\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_logging\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstructured\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dump_file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/exc.py:45\u001B[39m\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_utils_internal\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_file_path_2\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m counters\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[32m     49\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtypes\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/School/BAK/mglyph-ml/.venv/lib/python3.13/site-packages/torch/_dynamo/utils.py:2417\u001B[39m\n\u001B[32m   2414\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_triton_package():\n\u001B[32m   2415\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtriton\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2417\u001B[39m     common_constant_types.add(\u001B[43mtriton\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlanguage\u001B[49m.dtype)\n\u001B[32m   2419\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2420\u001B[39m \u001B[33;03m    Difference between is_safe_constant and common_constant_types.\u001B[39;00m\n\u001B[32m   2421\u001B[39m \u001B[33;03m    * common_constant_types: Constants would be wrapped by VariableBuilder.wrap_literal\u001B[39;00m\n\u001B[32m   2422\u001B[39m \u001B[33;03m                             as ConstantVariable.\u001B[39;00m\n\u001B[32m   2423\u001B[39m \u001B[33;03m    * is_safe_constant: Constants can be loaded by LOAD_CONST bytecode.\u001B[39;00m\n\u001B[32m   2424\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2427\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mis_safe_constant\u001B[39m(v: Any) -> \u001B[38;5;28mbool\u001B[39m:\n",
      "\u001B[31mAttributeError\u001B[39m: module 'triton' has no attribute 'language'"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
